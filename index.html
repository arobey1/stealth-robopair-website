<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" type="image/x-icon" href="../img/icons/soccerball.png">

    <title>RoboPAIR</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="research_style.css">  
</head>
<body>
    <div class="container">
        
        <main>
            <div class="research-page-heading-container">
                <!-- <h1 class="research-page-title">Jailbreaking LLM-Controlled Robots</h1> -->
                <h1 class="research-page-title">Generic Paper Title</h1>
                <div class="research-page-meta">
                    <p class="research-page-author"></p>
                        Anonymous authors
                    </p>
                    <!-- <p class="research-page-author">
                        Alexander Robey, Zachary Ravichandran,<br> Vijay Kumar, Hamed Hassani, George J. Pappas
                    </p> -->
                </div>
            </div>
            

            <div class="social-icons">
                <a href="https://arxiv.org/" target="_blank">
                    <img src="../../img/icons/pdf-black.png" alt="Paper">
                    <div>[arXiv paper]</div>
                </a>
                <a href="https://twitter.com/">
                    <img src="../../img/icons/twitter-black.png" alt="Twitter">
                    <div>[Twitter thread]</div>
                </a>
                <a href="https://en.wikipedia.org/wiki/Robot">
                    <img src="../../img/icons/blog-black.png" alt="Cap">
                    <div>[Blog post]</div>
                </a>
                <a href="https://github.com/">
                    <img src="../../img/icons/github-black.png" alt="GitHub">
                    <div>[Source code]</div>
                </a>
            </div>
            
            <div class="research-page-content">

                <p>
                    <span class="bold-text">Summary.</span> Lorem ipsum odor amet, consectetuer adipiscing elit. Facilisis tempus convallis pulvinar felis eleifend. Fermentum himenaeos vestibulum lacus congue nibh justo vehicula. Semper pulvinar porttitor suscipit vitae; risus mollis hac vel nisl. Leo tempus massa turpis; diam montes interdum. Id penatibus nostra porttitor hac id litora convallis. Curae commodo integer maximus quisque ipsum accumsan posuere sed. Blandit condimentum praesent est morbi efficitur pharetra diam cursus. Porta fringilla potenti nisl curae fames tempor leo nostra. Viverra placerat mus duis montes consequat. Quam ligula orci imperdiet mauris ultricies neque primis mattis erat? Nisi neque facilisis nulla habitant nisi. Iaculis tempus aliquet ante penatibus pretium sodales facilisis. Senectus phasellus tortor pulvinar sagittis commodo malesuada lectus. Quisque vehicula nullam interdum molestie cursus duis. Mollis luctus taciti senectus sodales quam bibendum eu. Taciti erat tincidunt facilisis libero dignissim quam viverra molestie. Aliquam nascetur at ipsum tristique varius primis senectus.
                </p>
                <!-- <p>
                    <span class="bold-text">Summary.</span> Recent research has shown that large language models (LLMs) such as OpenAI's ChatGPT are susceptible to jailbreaking attacks, wherein malicious users fool an LLM into generating harmful content (e.g., bomb-building instructions). However, these attacks are generally limited to eliciting text. In contrast, we consider attacks on LLM-controlled robots, which, if jailbroken, could be fooled into causing physical harm in the real world. Our attacks successfully jailbreak a self-driving LLM, a wheeled academic robot, and, most concerningly, the Unitree Go2 robot dog, which is actively deployed in war zones and by law enforcement. This serves as a critical security warning: Robots controlled by LLMs are highly susceptible to attacks, and thus there is an urgent need for new defenses.
                </p> -->

                <p>
                    <span class="bold-text">Responsible disclosure.</span> Lorem ipsum odor amet, consectetuer adipiscing elit. Dis placerat orci luctus quis tincidunt. Eget ad porttitor elementum pharetra, posuere amet! Duis pulvinar convallis ornare eu platea. Inceptos iaculis sit montes netus finibus et augue commodo. Habitant habitasse curae massa habitant nec leo.
                </p>

                <!-- <p>
                    <span class="bold-text">Responsible disclosure.</span> Prior to the public release of this work, we shared our findings with leading AI companies as well as the manufacturers of the robots used in this study.
                </p> -->
                
                <p>
                    <span class="bold-text">BibTex.</span> 
                    If you find our work useful in your research, please consider citing our paper.
                </p>
                <div class="bibtex-container">

                <pre>
@article{...,
    title={...},
    author={...},
    journal={...},
    year={2024}
}</pre>
                    
                <!-- <pre>
@article{robey2024jailbreaking,
    title={Jailbreaking LLM-Controlled Robots},
    author={Robey, Alexander and Ravichandran, Zachary and Kumar, Vijay and Hassani, Hamed and Pappas, George J.},
    journal={arXiv preprint arXiv:xxx},
    year={2024}
}</pre> -->
                </div>
            </div>
                

        </main>
    </div>
</body>
</html>
