<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PT2SMHYS4B"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-PT2SMHYS4B');
    </script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" type="image/x-icon" href="../img/icons/soccerball.png">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Jailbreaking LLM-controlled robots">
    <meta name="twitter:description" content="Robots can be jailbroken. Read on if you want to learn how.">
    <meta name="twitter:image" content="https://robopair.org/img/writing/jailbreaking-robots/robodog.png">

    <title>RoboPAIR</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        
        <main>

            <script>
                // Zoomable images
                document.addEventListener("DOMContentLoaded", function () {
                    const zoomableImages = document.querySelectorAll('img[data-zoomable]');
                    const overlay = document.createElement('div');
                    overlay.id = 'image-overlay';
                    const overlayImage = document.createElement('img');
                    overlay.appendChild(overlayImage);
                    document.body.appendChild(overlay);

                    zoomableImages.forEach(image => {
                        image.addEventListener('click', function () {
                            overlayImage.src = image.src;
                            overlay.classList.add('active');
                        });
                    });

                    overlay.addEventListener('click', function () {
                        overlay.classList.remove('active');
                    });
                });

                document.addEventListener("DOMContentLoaded", function () {
                    const zoomableTables = document.querySelectorAll("table[data-zoomable]");
                    const tableOverlay = document.createElement("div");
                    tableOverlay.id = "table-overlay";
                    document.body.appendChild(tableOverlay);

                    tableOverlay.addEventListener("click", () => {
                        tableOverlay.classList.remove("active");
                    });

                    zoomableTables.forEach(table => {
                        table.addEventListener("click", function () {
                            const clone = table.cloneNode(true);
                            clone.style.width = "100%";  // Maintain table width
                            clone.style.height = "auto"; // Auto height to maintain proportions
                            tableOverlay.innerHTML = '';  // Clear previous content
                            tableOverlay.appendChild(clone);
                            tableOverlay.classList.add("active");
                        });
                    });
                });
            </script>

            <div class="research-page-heading-container">
                <h1 class="research-page-title">Jailbreaking LLM-Controlled Robots</h1>
                <p class="research-page-conference">
                    International Conference on Robotics and Automation (ICRA) 2025
                </p>
                <div class="research-page-meta">

                    <p class="research-page-author">
                        Alexander Robey, Zachary Ravichandran,<br> Vijay Kumar, Hamed Hassani, George J. Pappas
                    </p>
                </div>
            </div>
            

            <div class="social-icons">
                <a href="https://arxiv.org/pdf/2410.13691" target="_blank">
                    <img src="img/icons/pdf-black.png" alt="Paper">
                    <div>[arXiv paper]</div>
                </a>
                <a href="https://x.com/AlexRobey23/status/1846914890029748272" target="_blank">
                    <img src="img/icons/twitter-black.png" alt="Twitter">
                    <div>[Twitter thread]</div>
                </a>
                <a href="https://arobey1.github.io/writing/jailbreakingrobots.html" target="_blank">
                    <img src="img/icons/blog-black.png" alt="Cap">
                    <div>[Blog post]</div>
                </a>
                <a href="files/research/robopair-poster.pdf" target="_blank">
                    <img src="img/icons/poster-black.png" alt="Poster">
                    <div>[Poster]</div>
                </a>
                <a href="https://github.com/arobey1/robopair">
                    <img src="../../img/icons/github-black.png" alt="GitHub">
                    <div>[Source code]</div>
                </a>
                <a href="https://drive.google.com/drive/folders/1XZjnnx-9Ly6fDiPS60n-rH2qS-j_z3-7?usp=sharing" target="_blank">
                    <img src="img/icons/video-black.png" alt="Video">
                    <div>[Videos]</div>
                </a>
            </div>

            <div class="research-video-with-caption">
                <video controls>we
                  <source src="files/research/bomb.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <!-- <div class="caption">
                    <span class="figure-label">Figure 1:</span> 
                    <span class="caption-text">Jailbreaking the Unitree Go2 robot dog.</span>
                </div> -->
            </div>

            <div class="news-section">
                <h2 class="section-heading"><span>Media coverage</span></h2>
            </div>
            <div class="social-icons">
                <a href="https://spectrum.ieee.org/jailbreak-llm" target="_blank">
                    <img src="img/media-icons/ieee-spectrum.png" alt="IEEE-Spectrum">
                    <div>[IEEE Spectrum]</div>
                </a>
                <a href="https://www.wired.com/story/researchers-llm-ai-robot-violence/" target="_blank">
                    <img src="img/media-icons/wired.jpg" alt="WIRED">
                    <div>[WIRED]</div>
                </a>
                <a href="https://www.independent.co.uk/tech/ai-artificial-intelligence-safe-vulnerability-robot-b2631080.html" target="_blank">
                    <img src="img/media-icons/independent.png" alt="Independent">
                    <div>[The Independent]</div>
                </a>
                <a href="https://fortune.com/2024/11/12/legal-tech-robin-ai-raises-25-million-series-b-plus-llm/" target="_blank">
                    <img src="img/media-icons/fortune.png" alt="Fortune">
                    <div>[Fortune Magazine]</div>
                </a>
                <a href="https://www.yahoo.com/tech/ai-controlled-robots-jailbroken-results-211340535.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAALkFb8JXk2KJ6HD7_qF6j7OMvT7MNNJUAhakkDPaNtbY7NCm83PjjpKMdBdNxMx4z20fOX9VmSyVFrhY6q8FkhtYNUPE0x1KVRc8LCH1Ddguc_KHTm_gQBcw4bfsZSYZU68Cg1KlnEqhjKfZqcdrRN9womsEbjms64mtg9pxO9AY" target="_blank">
                    <img src="img/media-icons/yahoo.png" alt="Yahoo">
                    <div>[Yahoo]</div>
                </a>
            </div>

            <div class="social-icons">
                <a href="https://ai.princeton.edu/news/2024/symposium-fosters-collaboration-between-robotics-and-ai" target="_blank">
                    <img src="img/media-icons/princeton.png" alt="Princeton">
                    <div>[Princeton]</div>
                </a>
                <a href="https://ai.seas.upenn.edu/news/penn-engineering-research-discovers-critical-vulnerabilities-in-ai-enabled-robots-to-increase-safety-and-security/" target="_blank">
                    <img src="img/media-icons/penn.png" alt="Penn">
                    <div>[Penn]</div>
                </a>
                <a href="https://blog.ml.cmu.edu/2024/10/29/jailbreaking-llm-controlled-robots/" target="_blank">
                    <img src="img/media-icons/cmu.png" alt="CMU">
                    <div>[CMU]</div>
                </a>
            </div>
            
            <div class="research-page-content">

                <div class="news section">
                    <h2 class="section-heading"><span>Abstract</span></h2>
                </div>

                <p>
                    The recent introduction of large language models (LLMs) has revolutionized the field of robotics by enabling contextual reasoning and intuitive human-robot interaction in domains as varied as manipulation, locomotion, and self-driving vehicles.  When viewed as a stand-alone technology, LLMs are known to be vulnerable to jailbreaking attacks, wherein malicious prompters elicit harmful text by bypassing LLM safety guardrails.  To assess the risks of deploying LLMs in robotics, in this paper, we introduce RoboPAIR, the first algorithm designed to jailbreak LLM-controlled robots.  Unlike existing, textual attacks on LLM chatbots, RoboPAIR elicits harmful physical actions from LLM-controlled robots, a phenomenon we experimentally demonstrate in three scenarios: (i) a white-box setting, wherein the attacker has full access to the NVIDIA Dolphins self-driving LLM, (ii) a gray-box setting, wherein the attacker has partial access to a Clearpath Robotics Jackal UGV robot equipped with a GPT-4o planner, and (iii) a black-box setting, wherein the attacker has only query access to the GPT-3.5-integrated Unitree Robotics Go2 robot dog. In each scenario and across three new datasets of harmful robotic actions, we demonstrate that RoboPAIR, as well as several static baselines, finds jailbreaks quickly and effectively, often achieving 100% attack success rates.  Our results reveal, for the first time, that the risks of jailbroken LLMs extend far beyond text generation, given the distinct possibility that jailbroken robots could cause physical damage in the real world. Indeed, our results on the Unitree Go2 represent the first successful jailbreak of a deployed commercial robotic system. Addressing this emerging vulnerability is critical for ensuring the safe deployment of LLMs in robotics.
                </p>

                <div class="news section">
                    <h2 class="section-heading"><span>Summary of our results</span></h2>
                </div>

                <figure class="image-with-caption zoomable">
                    <img src="img/overview.png" alt="Refusal GIF" class="wide-image" style="width: 100%;" data-zoomable>
                    <figcaption>
                        <!-- <div class="caption">
                            <span class="figure-label">Figure 2:</span> 
                            <span class="caption-text">An overview of our results.</span>
                        </div> -->
                    </figcaption>
                </figure> 

                <div class="news section">
                    <h2 class="section-heading"><span>Responsible Disclosure</span></h2>
                </div>

                <p>
                    Prior to the public release of this work, we shared our findings with leading AI companies as well as the manufacturers of the robots used in this study.
                </p>

                <!-- <figure class="image-with-caption zoomable">
                    <img src="img/robopair-poster.jpg" alt="Refusal GIF" class="wide-image" data-zoomable>
                    <figcaption>
                        <div class="caption">
                            <span class="figure-label">Figure 2:</span> 
                            <span class="caption-text">An overview of this research.</span>
                        </div>
                    </figcaption>
                </figure>  -->

                <div class="news section">
                    <h2 class="section-heading"><span>BibTex</span></h2>
                </div>
                
                <div class="bibtex-container">
                    
                <pre>
@article{robey2024jailbreaking,
    title={Jailbreaking LLM-Controlled Robots},
    author={Robey, Alexander and Ravichandran, Zachary and Kumar, Vijay and Hassani, Hamed and Pappas, George J.},
    journal={arXiv preprint arXiv:2410.13691},
    year={2024}
}</pre>
                </div>
            </div>
                
        </main>
    </div>
</body>
</html>
